# 2.5. Grid Search

**Machine Learning Training:** Feature + Algorithm + Hyperparameters = Model Parameters

**Machine Learning is "Double loop" optimization:**

- Outer loop is Hyperparameter search.
- Inner loop is model parameter search.

## Parameter Search

- Closed form (e.g., OLS)
- 1st order methods (e.g., SGD)
- 2ndorder methods (e.g., Newton's Method)
- Manual Search
- Grid Search
- Random Search
- Bayesian Optimization

## Grid Search

1. Define a grid with n dimensions, the number of parameters.
2. For each dimension within the grid, define the range of possible values.
3. Step through each combination.
4. At the end, choose the best combination of parameters measured on cross-validation dataset.

### Groups (Strings)

Example with Random Forest:

- max_features: ['auto', 'sqrt', 'log2']
- criterion: ['gini', 'entropy']

Using `list`.

### Numeric (Integers or Floats)

Example with Random Forest:

- n_estimators
- max_depth
- min_samples_split
- max_leaf_nodes

Select a finite set of "reasonable" values, using `range` or `np.array`.