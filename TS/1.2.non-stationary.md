# 1.2. Univariance - Non-Stationary Time Series models

Transform the non-stationary time series so that the new time series is stationary and hence can be modeled with an ARMA model.

## ARIMA (autoregression integrated moving averages)

An ARIMA model models a non-stationary time series which after finitely many differences become stationary.

### Notation

$$
\begin{split}
\nabla & = 1-B \\
\nabla^d & = (1-B)^d \\
\nabla Y_t &= (1-B) Y_t = Y_t - Y_{t-1} \\
\nabla^d Y_t &= (1-B)^d Y_t
\end{split}
$$

If $d$ is a non-negative integer, then $\{Y_t\} \sim ARMA(p,d,q)$ if:
$$
x_t = (1-B)^d Y_t \sim ARMA(p,q)
$$
This definition implies an ARIMA($p,d,q$) model can be represented as follows:
$$
\begin{split}
\phi(B) X_t &= \theta(B) \varepsilon_t \\
\phi(B) (1-B)^d Y_t &= \theta(B) \varepsilon_t \\
\end{split}
$$
If $\{ Y_t \}$ exhibits polynomial trend of the form $m_t = \sum_{i=0}^d \alpha_i t^i$, then $\nabla^d Y_t$ will not have a trend component and $\nabla^{d+1} Y_t = 0$.

### Choose $d$

We determined this informally with plots or formally with hypothesis tests.

#### Graphically

* Plot of the time series: a lack of trend and constant variance informally indicate stationarity.
* ACF plots of time series: stationarity is indicated by rapid decay as apposed to slow decay.

#### Formally

Use "unit root tests", such as Augmented Dickey-Fuller.

$H_0$: time series is not stationary.

$H_a$: time series is stationary.

Fit an AR(p) model to the data and obtain the estimates $\hat{\phi}_1, \hat{\phi}_2, ..., \hat{\phi}_p$ and determine whether those are consistent with the stationary conditions. The order $p$ can be determined by the user, but automated implementations of this test chose by default as a large values of $p$ as can be.

Thus the $d$ is the numbers of iterations of the ADF test with the increasingly differenced data before the $H_0$ is rejected.

## SARIMA

A seasonal effect of period $m$ manifests itself as $s_t = s_{t \pm m}$. This sort of seasonal effect can be eliminated by finitely many applications of lag-$m$ differencing.

The goal is in general to use the ordinary differencing to eliminate trend and seasonal differencing to account for seasonality, thus both types of differencing maybe necessary.

### Notation

$$
\begin{split}
\nabla_k &= (1-B^k) \\
\nabla_k Y_t &= (1-B^k)Y_t = Y_t - Y_{t-k}
\end{split}
$$

$\{Y_t\} \sim SARMA(p,d,q) \times (P, D, Q)_m$ if:
$$
x_t = (1-B)^d (1-B^m)^D Y_t \sim ARMA(p,q)
$$
This definition implies a $SARMA(p,d,q) \times (P, D, Q)_m$ model can be represented as follows:
$$
\begin{split}
\phi^*(B) X_t &= \theta^*(B) \varepsilon_t \\
\text{where}\; \phi^*(B) &= \phi(B) \Phi(B^m)\\
\theta^*(B) &= \theta(B) \Theta(B) \\
\phi(B) &= 1 - \phi_1 Z - \phi_2 Z^2 - ... - \phi_p Z^p \\
\Phi(B) &= 1 - \Phi_1 Z - \Phi_2 Z^2 - ... - \Phi_p Z^p \\
\theta(B) &= 1 - \theta_1 Z - \theta_2 Z^2 - ... - \theta_p Z^p \\
\Theta(B) &= 1 - \Theta_1 Z - \Theta_2 Z^2 - ... - \Theta_p Z^p \\
\phi(B) \Phi(B) (1-B)^d (1-B^m)^D Y_t &= \theta(B) \Theta(B^m) \varepsilon_t
\end{split}
$$
The data within season can be viewed as within-season time series. The data between season can be viewed as a between-season time series. These two time series may have different ARMA representations.

* $p,q$ is ARMA orders of the within-season model.
* $P,Q$ is ARMA orders of the between-season model.

### Choose $m$

The period $m$ is the number of lag required for one iteration of the seasonal effect on an ACF plot.

## Box-Jankins Methodology

1. Check for non-constant variance and apply a transformation if necessary.

   * Log transformation ($\lambda = 0$)

   * Box-Cox transformation
     $$
     y^* = \bigg\{
     \begin{split}
     log(y) & \;\lambda = 0 \\
     \frac{y^\lambda -1}{\lambda} &\; \lambda \neq 0
     \end{split}
     $$

2. Check for seasonality and trend and difference as necessary.

   Chose $d, m, D$ such that $X_t = (1-B)^d (1-B^m)^D Y_t$ is stationary.

3. Identify $p,q,P,Q$ from ACF/PACF of the differenced data. Hence chose a model.

   * $p, q$ are chosen such that $\rho(1), \rho(2), ..., \rho(m-1)$ and $\alpha(1), \alpha(2), ..., \alpha(m-1)$ are consistent with $ARMA(p,q)$.
   * $P, Q$ are chosen such that $\rho(km)$ and $\alpha(km)$ for $k=1,2,3,...$ are consistent with $ARMA(P,Q)$.

4. Fit proposed model and iterate to an optional one.

5. Check using the residuals, that the model assumption are valid.

6. Forecast into the future.

